{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f9a637-7670-4dc3-9a4f-ad6aabaff9eb",
      "metadata": {
        "id": "38f9a637-7670-4dc3-9a4f-ad6aabaff9eb"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Setup and Imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "from collections import defaultdict, deque\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"NetworkX version: {nx.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "043c1662-6497-4619-b02d-0ecb598c5bea",
      "metadata": {
        "id": "043c1662-6497-4619-b02d-0ecb598c5bea"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Load OptiMoE Core Implementation\n",
        "# Paste the core implementation script here or import it\n",
        "from optimoe_networkx_core import *\n",
        "\n",
        "\n",
        "\n",
        "# Cell 3: Quick Test Run\n",
        "\"\"\"Quick test to verify everything works\"\"\"\n",
        "print(\"Running quick test simulation...\")\n",
        "\n",
        "# Create small test config\n",
        "test_sim = OptiMoENetworkSimulation()\n",
        "test_sim.moe_config.num_nodes = 16  # Small for quick test\n",
        "test_sim.moe_config.num_experts = 32\n",
        "\n",
        "# Run mini experiment\n",
        "test_baseline = test_sim.run_baseline_comparison(num_iterations=6)\n",
        "test_optimoe = test_sim.run_optimoe_experiment(num_iterations=30)\n",
        "\n",
        "print(f\"‚úÖ Test completed! OptiMoE made {sum(r['reconfigure'] for r in test_optimoe)} topology switches\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c28db94-dec5-4f1d-b8f2-06c794995619",
      "metadata": {
        "id": "1c28db94-dec5-4f1d-b8f2-06c794995619"
      },
      "outputs": [],
      "source": [
        "from optimoe_networkx_core import OptiMoENetworkSimulation\n",
        "\n",
        "# Cell 4: Main Experiment Runner\n",
        "\"\"\"Run full OptiMoE experiment with visualization\"\"\"\n",
        "\n",
        "def run_full_experiment(num_nodes=64, num_iterations=100):\n",
        "    \"\"\"Run complete OptiMoE experiment\"\"\"\n",
        "\n",
        "    print(f\"Starting OptiMoE Experiment\")\n",
        "    print(f\"Nodes: {num_nodes}, Iterations: {num_iterations}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Initialize simulation\n",
        "    sim = OptiMoENetworkSimulation()\n",
        "    sim.moe_config.num_nodes = num_nodes\n",
        "    sim.moe_config.num_experts = num_nodes * 8\n",
        "\n",
        "    # Run baseline\n",
        "    print(\"\\nüìä Running baseline experiments...\")\n",
        "    start_time = time.time()\n",
        "    baseline_results = sim.run_baseline_comparison(num_iterations=30)\n",
        "    baseline_time = time.time() - start_time\n",
        "\n",
        "    # Run OptiMoE\n",
        "    print(\"\\nüîÑ Running OptiMoE dynamic adaptation...\")\n",
        "    start_time = time.time()\n",
        "    optimoe_results = sim.run_optimoe_experiment(num_iterations=num_iterations)\n",
        "    optimoe_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n‚è±Ô∏è Timing: Baseline={baseline_time:.1f}s, OptiMoE={optimoe_time:.1f}s\")\n",
        "\n",
        "    return baseline_results, optimoe_results, sim\n",
        "\n",
        "# Run the experiment\n",
        "baseline_results, optimoe_results, sim = run_full_experiment(num_nodes=64, num_iterations=70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc70644-f21c-44ad-8ead-e95bada5f007",
      "metadata": {
        "id": "5cc70644-f21c-44ad-8ead-e95bada5f007"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Results Analysis and Visualization\n",
        "\"\"\"Comprehensive results visualization\"\"\"\n",
        "\n",
        "def visualize_optimoe_results(baseline_results, optimoe_results):\n",
        "    \"\"\"Create comprehensive visualization\"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # 1. Baseline Comparison\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    baseline_data = []\n",
        "    baseline_labels = []\n",
        "    for topo, results in baseline_results.items():\n",
        "        latencies = [r['average_latency'] for r in results]\n",
        "        baseline_data.append(latencies)\n",
        "        baseline_labels.append(topo)\n",
        "\n",
        "    bp = ax1.boxplot(baseline_data, labels=baseline_labels, patch_artist=True)\n",
        "    for patch, color in zip(bp['boxes'], ['lightblue', 'lightgreen', 'salmon']):\n",
        "        patch.set_facecolor(color)\n",
        "    ax1.set_ylabel('Latency (Œºs)')\n",
        "    ax1.set_title('Static Topology Performance')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. OptiMoE Latency Evolution\n",
        "    ax2 = fig.add_subplot(gs[0, 1:])\n",
        "    iterations = [r['iteration'] for r in optimoe_results]\n",
        "    latencies = [r['latency'] for r in optimoe_results]\n",
        "\n",
        "    # Color by topology\n",
        "    colors = {'fattree': 'blue', 'mesh': 'green', 'torus': 'red'}\n",
        "    for i in range(len(iterations)-1):\n",
        "        topo = optimoe_results[i]['topology']\n",
        "        ax2.plot([iterations[i], iterations[i+1]],\n",
        "                [latencies[i], latencies[i+1]],\n",
        "                color=colors[topo], alpha=0.7, linewidth=2)\n",
        "\n",
        "    # Mark reconfigurations\n",
        "    reconfig_points = [i for i, r in enumerate(optimoe_results) if r['reconfigure']]\n",
        "    if reconfig_points:\n",
        "        reconfig_lats = [latencies[i] for i in reconfig_points]\n",
        "        ax2.scatter([iterations[i] for i in reconfig_points],\n",
        "                   reconfig_lats, color='black', s=50, zorder=5,\n",
        "                   marker='v', label='Reconfiguration')\n",
        "\n",
        "    ax2.set_xlabel('Iteration')\n",
        "    ax2.set_ylabel('Latency (Œºs)')\n",
        "    ax2.set_title('OptiMoE Dynamic Adaptation')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Traffic Pattern Evolution\n",
        "    ax3 = fig.add_subplot(gs[1, :])\n",
        "    concentrations = [r['traffic_concentration'] for r in optimoe_results]\n",
        "    localities = [r['traffic_locality'] for r in optimoe_results]\n",
        "    variances = [r['traffic_variance'] for r in optimoe_results]\n",
        "\n",
        "    ax3.plot(iterations, concentrations, 'b-', label='Concentration', alpha=0.7)\n",
        "    ax3.plot(iterations, localities, 'g-', label='Locality', alpha=0.7)\n",
        "    ax3.plot(iterations, variances, 'r-', label='Variance', alpha=0.7)\n",
        "\n",
        "    # Shade regions by pattern\n",
        "    pattern_changes = [0, 15, 30, 45, 60, 75, 90]\n",
        "    pattern_names = ['Hotspot', 'Uniform', 'Regional', 'Skewed'] * 10\n",
        "    for i in range(len(pattern_changes)-1):\n",
        "        start = pattern_changes[i]\n",
        "        end = pattern_changes[i+1] if i+1 < len(pattern_changes) else 100\n",
        "        pattern = pattern_names[i % 4]\n",
        "        color = ['pink', 'lightblue', 'lightgreen', 'lightyellow'][i % 4]\n",
        "        ax3.axvspan(start, end, alpha=0.2, color=color)\n",
        "        ax3.text((start+end)/2, 0.9, pattern, ha='center', fontsize=8)\n",
        "\n",
        "    ax3.set_xlabel('Iteration')\n",
        "    ax3.set_ylabel('Traffic Characteristics')\n",
        "    ax3.set_title('Traffic Pattern Evolution')\n",
        "    ax3.legend(loc='lower right')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Topology Usage Timeline\n",
        "    ax4 = fig.add_subplot(gs[2, 0:2])\n",
        "\n",
        "    # Create timeline visualization\n",
        "    topology_timeline = []\n",
        "    current_topo = optimoe_results[0]['topology']\n",
        "    start_idx = 0\n",
        "\n",
        "    for i, result in enumerate(optimoe_results):\n",
        "        if result['topology'] != current_topo or i == len(optimoe_results)-1:\n",
        "            topology_timeline.append({\n",
        "                'topology': current_topo,\n",
        "                'start': start_idx,\n",
        "                'end': i\n",
        "            })\n",
        "            current_topo = result['topology']\n",
        "            start_idx = i\n",
        "\n",
        "    # Plot timeline bars\n",
        "    y_pos = 0\n",
        "    for segment in topology_timeline:\n",
        "        width = segment['end'] - segment['start']\n",
        "        color = colors[segment['topology']]\n",
        "        ax4.barh(y_pos, width, left=segment['start'], color=color,\n",
        "                alpha=0.7, edgecolor='black', linewidth=1)\n",
        "\n",
        "    ax4.set_xlim(0, len(optimoe_results))\n",
        "    ax4.set_ylim(-0.5, 0.5)\n",
        "    ax4.set_xlabel('Iteration')\n",
        "    ax4.set_yticks([])\n",
        "    ax4.set_title('Topology Selection Timeline')\n",
        "\n",
        "    # Add legend\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [Patch(facecolor=colors[t], label=t) for t in colors.keys()]\n",
        "    ax4.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "    # 5. Performance Metrics\n",
        "    ax5 = fig.add_subplot(gs[2, 2])\n",
        "\n",
        "    # Calculate metrics\n",
        "    baseline_avg = np.mean([lat for results in baseline_data for lat in results])\n",
        "    optimoe_avg = np.mean(latencies)\n",
        "    improvement = (baseline_avg - optimoe_avg) / baseline_avg * 100\n",
        "\n",
        "    reconfigs = sum(1 for r in optimoe_results if r['reconfigure'])\n",
        "    reconfig_rate = reconfigs / len(optimoe_results) * 100\n",
        "\n",
        "    # Topology usage\n",
        "    topo_usage = defaultdict(int)\n",
        "    for r in optimoe_results:\n",
        "        topo_usage[r['topology']] += 1\n",
        "\n",
        "    # Create metrics text\n",
        "    metrics_text = f\"\"\"Performance Summary\n",
        "    {'='*25}\n",
        "\n",
        "    Baseline Avg: {baseline_avg:.1f} Œºs\n",
        "    OptiMoE Avg:  {optimoe_avg:.1f} Œºs\n",
        "    Improvement:  {improvement:+.1f}%\n",
        "\n",
        "    Reconfigurations: {reconfigs}\n",
        "    Switch Rate: {reconfig_rate:.1f}%\n",
        "\n",
        "    Topology Usage:\n",
        "    \"\"\"\n",
        "\n",
        "    for topo, count in topo_usage.items():\n",
        "        pct = count / len(optimoe_results) * 100\n",
        "        metrics_text += f\"\\n  {topo}: {pct:.1f}%\"\n",
        "\n",
        "    ax5.text(0.1, 0.9, metrics_text, transform=ax5.transAxes,\n",
        "            fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
        "    ax5.axis('off')\n",
        "\n",
        "    plt.suptitle('OptiMoE: Dynamic Topology-Aware Scheduling Results',\n",
        "                fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Generate visualization\n",
        "fig = visualize_optimoe_results(baseline_results, optimoe_results)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e706cb9f-f78f-4249-899e-853b19bbabbc",
      "metadata": {
        "id": "e706cb9f-f78f-4249-899e-853b19bbabbc"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Detailed Performance Analysis\n",
        "\"\"\"Analyze switching decisions and their effectiveness\"\"\"\n",
        "\n",
        "def analyze_switching_decisions(optimoe_results):\n",
        "    \"\"\"Analyze the effectiveness of topology switches\"\"\"\n",
        "\n",
        "    switches = []\n",
        "    for i, result in enumerate(optimoe_results):\n",
        "        if result['reconfigure']:\n",
        "            # Look at performance before and after switch\n",
        "            before_window = 5\n",
        "            after_window = 5\n",
        "\n",
        "            before_start = max(0, i - before_window)\n",
        "            after_end = min(len(optimoe_results), i + after_window)\n",
        "\n",
        "            before_latencies = [optimoe_results[j]['latency']\n",
        "                              for j in range(before_start, i)]\n",
        "            after_latencies = [optimoe_results[j]['latency']\n",
        "                             for j in range(i, after_end)]\n",
        "\n",
        "            if before_latencies and after_latencies:\n",
        "                before_avg = np.mean(before_latencies)\n",
        "                after_avg = np.mean(after_latencies)\n",
        "                improvement = (before_avg - after_avg) / before_avg * 100\n",
        "\n",
        "                switches.append({\n",
        "                    'iteration': i,\n",
        "                    'from_topology': optimoe_results[i-1]['topology'] if i > 0 else 'unknown',\n",
        "                    'to_topology': result['topology'],\n",
        "                    'before_latency': before_avg,\n",
        "                    'after_latency': after_avg,\n",
        "                    'improvement': improvement,\n",
        "                    'traffic_concentration': result['traffic_concentration'],\n",
        "                    'traffic_locality': result['traffic_locality']\n",
        "                })\n",
        "\n",
        "    # Print analysis\n",
        "    print(\"Topology Switch Analysis\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for i, switch in enumerate(switches):\n",
        "        print(f\"\\nSwitch {i+1} at iteration {switch['iteration']}:\")\n",
        "        print(f\"  {switch['from_topology']} ‚Üí {switch['to_topology']}\")\n",
        "        print(f\"  Before: {switch['before_latency']:.1f} Œºs\")\n",
        "        print(f\"  After:  {switch['after_latency']:.1f} Œºs\")\n",
        "        print(f\"  Improvement: {switch['improvement']:+.1f}%\")\n",
        "        print(f\"  Traffic: concentration={switch['traffic_concentration']:.2f}, \"\n",
        "              f\"locality={switch['traffic_locality']:.2f}\")\n",
        "\n",
        "    # Overall statistics\n",
        "    if switches:\n",
        "        avg_improvement = np.mean([s['improvement'] for s in switches])\n",
        "        successful_switches = sum(1 for s in switches if s['improvement'] > 0)\n",
        "\n",
        "        print(f\"\\nOverall Switch Statistics:\")\n",
        "        print(f\"  Total switches: {len(switches)}\")\n",
        "        print(f\"  Successful switches: {successful_switches}/{len(switches)} \"\n",
        "              f\"({successful_switches/len(switches)*100:.1f}%)\")\n",
        "        print(f\"  Average improvement: {avg_improvement:+.1f}%\")\n",
        "\n",
        "    return switches\n",
        "\n",
        "# Analyze switching decisions\n",
        "switch_analysis = analyze_switching_decisions(optimoe_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cb140b0-17d7-4c8b-8b47-e7ec12179fa3",
      "metadata": {
        "id": "8cb140b0-17d7-4c8b-8b47-e7ec12179fa3"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Export Results for Paper\n",
        "\"\"\"Export results in format suitable for paper\"\"\"\n",
        "\n",
        "def export_paper_results(baseline_results, optimoe_results, switch_analysis):\n",
        "    \"\"\"Export results for paper\"\"\"\n",
        "\n",
        "    # Calculate key metrics\n",
        "    baseline_latencies = []\n",
        "    for topo, results in baseline_results.items():\n",
        "        baseline_latencies.extend([r['average_latency'] for r in results])\n",
        "\n",
        "    optimoe_latencies = [r['latency'] for r in optimoe_results]\n",
        "\n",
        "    baseline_avg = np.mean(baseline_latencies)\n",
        "    optimoe_avg = np.mean(optimoe_latencies)\n",
        "    improvement = (baseline_avg - optimoe_avg) / baseline_avg * 100\n",
        "\n",
        "    # Create results dictionary\n",
        "    paper_results = {\n",
        "        'configuration': {\n",
        "            'num_nodes': 64,\n",
        "            'num_experts': 128,\n",
        "            'num_iterations': len(optimoe_results)\n",
        "        },\n",
        "        'baseline': {\n",
        "            'average_latency': baseline_avg,\n",
        "            'std_latency': np.std(baseline_latencies),\n",
        "            'min_latency': np.min(baseline_latencies),\n",
        "            'max_latency': np.max(baseline_latencies)\n",
        "        },\n",
        "        'optimoe': {\n",
        "            'average_latency': optimoe_avg,\n",
        "            'std_latency': np.std(optimoe_latencies),\n",
        "            'min_latency': np.min(optimoe_latencies),\n",
        "            'max_latency': np.max(optimoe_latencies),\n",
        "            'num_switches': len(switch_analysis),\n",
        "            'switch_rate': len(switch_analysis) / len(optimoe_results) * 100\n",
        "        },\n",
        "        'improvement': {\n",
        "            'percentage': improvement,\n",
        "            'absolute_Œºs': baseline_avg - optimoe_avg\n",
        "        },\n",
        "        'topology_usage': {},\n",
        "        'switch_effectiveness': {\n",
        "            'average_improvement': np.mean([s['improvement'] for s in switch_analysis]) if switch_analysis else 0,\n",
        "            'successful_rate': sum(1 for s in switch_analysis if s['improvement'] > 0) / len(switch_analysis) * 100 if switch_analysis else 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Calculate topology usage\n",
        "    for r in optimoe_results:\n",
        "        topo = r['topology']\n",
        "        if topo not in paper_results['topology_usage']:\n",
        "            paper_results['topology_usage'][topo] = 0\n",
        "        paper_results['topology_usage'][topo] += 1\n",
        "\n",
        "    # Convert to percentages\n",
        "    total = len(optimoe_results)\n",
        "    for topo in paper_results['topology_usage']:\n",
        "        count = paper_results['topology_usage'][topo]\n",
        "        paper_results['topology_usage'][topo] = {\n",
        "            'count': count,\n",
        "            'percentage': count / total * 100\n",
        "        }\n",
        "\n",
        "    # Save to JSON\n",
        "    with open('optimoe_paper_results.json', 'w') as f:\n",
        "        json.dump(paper_results, f, indent=2)\n",
        "\n",
        "    # Print LaTeX-ready table\n",
        "    print(\"\\nLaTeX Table for Paper:\")\n",
        "    print(\"=\"*60)\n",
        "    print(r\"\\begin{table}[h]\")\n",
        "    print(r\"\\centering\")\n",
        "    print(r\"\\caption{OptiMoE Performance Results}\")\n",
        "    print(r\"\\begin{tabular}{lcc}\")\n",
        "    print(r\"\\toprule\")\n",
        "    print(r\"Metric & Baseline & OptiMoE \\\\\")\n",
        "    print(r\"\\midrule\")\n",
        "    print(f\"Average Latency (Œºs) & {baseline_avg:.1f} & {optimoe_avg:.1f} \\\\\\\\\")\n",
        "    print(f\"Std. Deviation (Œºs) & {np.std(baseline_latencies):.1f} & {np.std(optimoe_latencies):.1f} \\\\\\\\\")\n",
        "    print(f\"Min Latency (Œºs) & {np.min(baseline_latencies):.1f} & {np.min(optimoe_latencies):.1f} \\\\\\\\\")\n",
        "    print(f\"Max Latency (Œºs) & {np.max(baseline_latencies):.1f} & {np.max(optimoe_latencies):.1f} \\\\\\\\\")\n",
        "    print(r\"\\midrule\")\n",
        "    print(f\"Improvement & - & {improvement:+.1f}\\\\% \\\\\\\\\")\n",
        "    print(f\"Reconfigurations & - & {len(switch_analysis)} \\\\\\\\\")\n",
        "    print(f\"Switch Rate & - & {len(switch_analysis)/len(optimoe_results)*100:.1f}\\\\% \\\\\\\\\")\n",
        "    print(r\"\\bottomrule\")\n",
        "    print(r\"\\end{tabular}\")\n",
        "    print(r\"\\end{table}\")\n",
        "\n",
        "    return paper_results\n",
        "\n",
        "# Export results\n",
        "paper_results = export_paper_results(baseline_results, optimoe_results, switch_analysis)\n",
        "print(f\"\\n‚úÖ Results exported to 'optimoe_paper_results.json'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b97832-9732-4308-9b02-8d336091e6fb",
      "metadata": {
        "id": "28b97832-9732-4308-9b02-8d336091e6fb"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Scalability Test\n",
        "\"\"\"Test OptiMoE scalability with different cluster sizes\"\"\"\n",
        "\n",
        "def test_scalability():\n",
        "    \"\"\"Test OptiMoE with different cluster sizes\"\"\"\n",
        "\n",
        "    cluster_sizes = [16, 32, 64, 128]\n",
        "    results = []\n",
        "\n",
        "    print(\"Scalability Test\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    for size in cluster_sizes:\n",
        "        print(f\"\\nTesting {size} nodes...\")\n",
        "\n",
        "        # Create simulation\n",
        "        sim = OptiMoENetworkSimulation()\n",
        "        sim.moe_config.num_nodes = size\n",
        "        sim.moe_config.num_experts = size * 4\n",
        "\n",
        "        # Run short experiments\n",
        "        baseline = sim.run_baseline_comparison(num_iterations=5)\n",
        "        optimoe = sim.run_optimoe_experiment(num_iterations=40)\n",
        "\n",
        "        # Calculate metrics\n",
        "        baseline_avg = np.mean([r['average_latency']\n",
        "                               for results in baseline.values()\n",
        "                               for r in results])\n",
        "        optimoe_avg = np.mean([r['latency'] for r in optimoe])\n",
        "        improvement = (baseline_avg - optimoe_avg) / baseline_avg * 100\n",
        "        switches = sum(1 for r in optimoe if r['reconfigure'])\n",
        "\n",
        "        results.append({\n",
        "            'size': size,\n",
        "            'baseline': baseline_avg,\n",
        "            'optimoe': optimoe_avg,\n",
        "            'improvement': improvement,\n",
        "            'switches': switches\n",
        "        })\n",
        "\n",
        "        print(f\"  Baseline: {baseline_avg:.1f} Œºs\")\n",
        "        print(f\"  OptiMoE:  {optimoe_avg:.1f} Œºs\")\n",
        "        print(f\"  Improvement: {improvement:+.1f}%\")\n",
        "\n",
        "    # Plot scaling results\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    sizes = [r['size'] for r in results]\n",
        "    improvements = [r['improvement'] for r in results]\n",
        "    switches = [r['switches'] for r in results]\n",
        "\n",
        "    ax1.plot(sizes, improvements, 'o-', linewidth=2, markersize=8)\n",
        "    ax1.set_xlabel('Cluster Size (nodes)')\n",
        "    ax1.set_ylabel('Performance Improvement (%)')\n",
        "    ax1.set_title('OptiMoE Scalability')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_xscale('log', base=2)\n",
        "\n",
        "    ax2.plot(sizes, switches, 'o-', linewidth=2, markersize=8, color='orange')\n",
        "    ax2.set_xlabel('Cluster Size (nodes)')\n",
        "    ax2.set_ylabel('Number of Topology Switches')\n",
        "    ax2.set_title('Reconfiguration Frequency')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_xscale('log', base=2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run scalability test (optional - takes time)\n",
        "scalability_results = test_scalability()\n",
        "print(\"Scalability test ready. Uncomment the line above to run.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d73002-f4c1-4053-9dbe-3719b3a30557",
      "metadata": {
        "id": "51d73002-f4c1-4053-9dbe-3719b3a30557"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}